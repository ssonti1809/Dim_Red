{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# CS246 - Colab 3\n",
        "## K-Means & PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's set up the necessary libraries for this Colab. Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "k-qHai2252mI"
      },
      "outputs": [],
      "source": [
        "# Install scikit-learn if needed (usually pre-installed in Colab)\n",
        "!pip install -q scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "Now we import some of the libraries usually needed by our workload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrJlMBt1Ela"
      },
      "source": [
        "Let's verify the imports are working correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH91tEik9zZ3",
        "outputId": "ec054ef5-225c-4288-f174-053abe3cd284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Verify scikit-learn is available\n",
        "import sklearn\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXdMR6wnEIM"
      },
      "source": [
        "In this Colab, rather than downloading a file from Google Drive, we will load a famous machine learning dataset, the [Breast Cancer Wisconsin dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html), using the ```scikit-learn``` datasets loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsaYOqRxar2"
      },
      "source": [
        "For convenience, we will construct a Pandas dataframe from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oitav_xhQD9w",
        "outputId": "1b51a312-5457-4c8c-ec59-87cba7ce0e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (569, 30)\n",
            "\n",
            "Column names:\n",
            "  - mean radius\n",
            "  - mean texture\n",
            "  - mean perimeter\n",
            "  - mean area\n",
            "  - mean smoothness\n",
            "  - mean compactness\n",
            "  - mean concavity\n",
            "  - mean concave points\n",
            "  - mean symmetry\n",
            "  - mean fractal dimension\n",
            "  - radius error\n",
            "  - texture error\n",
            "  - perimeter error\n",
            "  - area error\n",
            "  - smoothness error\n",
            "  - compactness error\n",
            "  - concavity error\n",
            "  - concave points error\n",
            "  - symmetry error\n",
            "  - fractal dimension error\n",
            "  - worst radius\n",
            "  - worst texture\n",
            "  - worst perimeter\n",
            "  - worst area\n",
            "  - worst smoothness\n",
            "  - worst compactness\n",
            "  - worst concavity\n",
            "  - worst concave points\n",
            "  - worst symmetry\n",
            "  - worst fractal dimension\n"
          ]
        }
      ],
      "source": [
        "pd_df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "print(f\"Dataset shape: {pd_df.shape}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "for col in pd_df.columns:\n",
        "    print(f\"  - {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtR1xRvonxiO"
      },
      "source": [
        "With the next cell, we build the two data structures that we will be using throughout this Colab:\n",
        "\n",
        "\n",
        "*   ```features```, a numpy array containing all the original features in the dataset;\n",
        "*   ```labels```, an array of binary labels indicating if the corresponding set of features belongs to a subject with breast cancer, or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GP23Xkgwi0SD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f49b056-5b8f-4842-e9ea-fa0999985d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (569, 30)\n",
            "Labels shape: (569,)\n"
          ]
        }
      ],
      "source": [
        "features = breast_cancer.data\n",
        "labels = breast_cancer.target\n",
        "\n",
        "print(f\"Features shape: {features.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLNUxP0_8x3"
      },
      "source": [
        "If you run successfully the Setup and Data Preprocessing stages, you are now ready to cluster the data with the [K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) algorithm included in scikit-learn.\n",
        "Set the ```n_clusters``` parameter to **2** and ```random_state``` to **1**, fit the model, and then compute the [Silhouette score](https://en.wikipedia.org/wiki/Silhouette_(clustering)) (i.e., a measure of quality of the obtained clustering, here we use squared euclidean distance).  \n",
        "\n",
        "**IMPORTANT:** use the scikit-learn implementation of the Silhouette score via ```silhouette_score```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0xVIfPHZwWaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63628e1e-a952-4340-e69e-868bd8985858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.6972646156059464\n"
          ]
        }
      ],
      "source": [
        "# 8-9 lines of code in total expected but can differ based on your style.\n",
        "# for sub-parts of the question, creating different cells of code would be recommended.\n",
        "# The running time should be less than 1 minute\n",
        "# YOUR CODE HERE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "kmeans = KMeans(n_clusters=2, random_state=1)\n",
        "kmeans.fit(features)\n",
        "predictions = kmeans.labels_\n",
        "score = silhouette_score(features, predictions)\n",
        "print(f\"Silhouette Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GB09n7sqTO6"
      },
      "source": [
        "Take the predictions produced by K-means, and compare them with the ```labels``` variable (i.e., the ground truth from our dataset).  \n",
        "\n",
        "Compute how many data points in the dataset have been clustered correctly (i.e., positive cases in one cluster, negative cases in the other), please use the best case scenario since the output cluster ids can be a permutation of labels.\n",
        "\n",
        "*HINT*: you can use ```np.count_nonzero(predictions == labels)``` to quickly compute the element-wise comparison of two arrays.\n",
        "\n",
        "**IMPORTANT**: K-means is a clustering algorithm, so it will not output a label for each data point, but just a cluster identifier!  As such, label ```0``` does not necessarily match the cluster identifier ```0```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WQhC3APIPPM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c757d635-776c-439a-e45a-3a231236dcfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly clustered (best case): 486 out of 569\n"
          ]
        }
      ],
      "source": [
        "# 4 lines of code in total expected but can differ based on your style.\n",
        "# for sub-parts of the question, creating different cells of code would be recommended.\n",
        "# YOUR CODE HERE\n",
        "match1 = np.count_nonzero(predictions == labels)\n",
        "match2 = np.count_nonzero(predictions != labels)\n",
        "print(f\"Correctly clustered (best case): {max(match1, match2)} out of {len(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLIprM1JsdTU"
      },
      "source": [
        "Now perform dimensionality reduction on the ```features``` using the [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) statistical procedure, available in scikit-learn.\n",
        "\n",
        "Set the ```n_components``` parameter to **2**, effectively reducing the dataset size of a **15X** factor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "p4J8JMDkSb24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3ddfe3-319e-4c62-d8ad-ccdd7bc0e999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fourth row after PCA: [-407.18080253  -67.38031982]\n"
          ]
        }
      ],
      "source": [
        "# 6 lines of code in total expected but can differ based on your style.\n",
        "# for sub-parts of the question, creating different cells of code would be recommended.\n",
        "# The running time should be less than 30 seconds.\n",
        "# Sanity check: the fourth row in the result should be [-692.6905100570509,38.57692259208171]\n",
        "# YOUR CODE HERE\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(features)\n",
        "print(\"Fourth row after PCA:\", pca_features[3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8leQR4-atMAl"
      },
      "source": [
        "Now run K-means with the same parameters as above, but on the ```pcaFeatures``` produced by the PCA reduction you just executed.\n",
        "\n",
        "Compute the Silhouette score, as well as the number of data points that have been clustered correctly (also the best case scenario)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "U_snSSj5k2y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f260555-950d-43e5-d09a-d7bd625f2a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score after PCA: 0.6984195775999954\n",
            "Correctly clustered after PCA (best case): 486 out of 569\n"
          ]
        }
      ],
      "source": [
        "# 11-13 lines of code in total expected but can differ based on your style.\n",
        "# for sub-parts of the question, creating different cells of code would be recommended.\n",
        "# YOUR CODE HERE\n",
        "# Run KMeans again on PCA-reduced features\n",
        "kmeans_pca = KMeans(n_clusters=2, random_state=1)\n",
        "kmeans_pca.fit(pca_features)\n",
        "pca_predictions = kmeans_pca.labels_\n",
        "score_pca = silhouette_score(pca_features, pca_predictions)\n",
        "print(f\"Silhouette Score after PCA: {score_pca}\")\n",
        "match1 = np.count_nonzero(pca_predictions == labels)\n",
        "match2 = np.count_nonzero(pca_predictions != labels)\n",
        "print(f\"Correctly clustered after PCA (best case): {max(match1, match2)} out of {len(labels)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}